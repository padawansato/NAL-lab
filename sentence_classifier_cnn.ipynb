{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentence_classifier_cnn.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjMGeMT9Uq3g",
        "colab_type": "code",
        "outputId": "491ae85b-7b72-4f0e-e97f-100a810c8fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "# !pip install hoge\n",
        "# ドライブをマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# カレントディレクトリの変更\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/NAL-LAB/Colab Notebooks/')\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/NAL-LAB/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxJUEk8ZU0rI",
        "colab_type": "code",
        "outputId": "cea897ee-967a-4c4d-c0e9-328c489c4489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "source": [
        "# google colab で chainer などを使うための設定\n",
        "\n",
        "# colab の cuda に応じて、いい感じに chainer と Cupy をインストールするコマンド\n",
        "!curl https://colab.chainer.org/install | sh -\n",
        "\n",
        "# chainer のインストール確認コマンド\n",
        "!python -c \"import chainer; chainer.print_runtime_info()\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1580  100  1580    0     0  11048      0 --:--:-- --:--:-- --:--:-- 11048\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "+ set +ex\n",
            "Installation succeeded!\n",
            "Platform: Linux-4.14.79+-x86_64-with-Ubuntu-18.04-bionic\n",
            "Chainer: 5.0.0\n",
            "NumPy: 1.14.6\n",
            "CuPy:\n",
            "  CuPy Version          : 5.2.0\n",
            "  CUDA Root             : /usr/local/cuda\n",
            "  CUDA Build Version    : 10000\n",
            "  CUDA Driver Version   : 10000\n",
            "  CUDA Runtime Version  : 10000\n",
            "  cuDNN Build Version   : 7301\n",
            "  cuDNN Version         : 7301\n",
            "  NCCL Build Version    : 2307\n",
            "iDeep: 2.0.0.post3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD-NspVkV9v-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer.training import extensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqc8vzCBVhin",
        "colab_type": "code",
        "outputId": "a1251352-0c5e-4568-e1b0-ea4acf72b3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('GPU availability:', chainer.cuda.available)\n",
        "print('cuDNN availablility:', chainer.cuda.cudnn_enabled)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU availability: True\n",
            "cuDNN availablility: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdsLvde1U-W1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import chainer\n",
        "from chainer import ChainList, optimizers, training\n",
        "from chainer.training import extensions\n",
        "import chainer.functions as F\n",
        "import chainer.links as L"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkR8fYpCVEnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [\n",
        "    [\"Could I exchange business cards, if you don’t mind?\", 1],\n",
        "    [\"I'm calling regarding the position advertised in the newspaper.\", 0],\n",
        "    [\"I'd like to apply for the programmer position.\", 0],\n",
        "    [\"Could you tell me what an applicant needs to submit?\", 1],\n",
        "    [\"Could you tell me what skills are required?\", 1],\n",
        "    [\"We will assist employees with training and skill development.\", 0],\n",
        "    [\"What kind of in-house training system do you have for your new recruits?\", 1],\n",
        "    [\"For office equipment I think rental is better.\", 0],\n",
        "    [\"Is promotion based on the seniority system?\", 1],\n",
        "    [\"What's still pending from February?\", 1],\n",
        "    [\"Which is better, rental or outright purchase?\", 1],\n",
        "    [\"General Administration should do all the preparations for stockholder meetings.\", 0],\n",
        "    [\"One of the elevators is out of order. When do you think you can have it fixed?\", 1],\n",
        "    [\"General Administration is in charge of office building maintenance.\", 0],\n",
        "    [\"Receptionists at the entrance hall belong to General Administration.\", 0],\n",
        "    [\"Who is managing the office supplies inventory?\", 1],\n",
        "    [\"Is there any difference in pay between males and females?\", 1],\n",
        "    [\"The General Administration Dept. is in charge of office maintenance.\", 0],\n",
        "    [\"Have you issued the meeting notice to shareholders?\", 1],\n",
        "    [\"What is an average annual income in Japan?\", 1],\n",
        "    [\"Many Japanese companies introduced the early retirement system.\", 0],\n",
        "    [\"How much did you pay for the office equipment?\", 1],\n",
        "    [\"Is the employee training very popular here?\", 1],\n",
        "    [\"What kind of amount do you have in mind?\", 1],\n",
        "    [\"We must prepare our financial statement by next Monday.\", 0],\n",
        "    [\"Would it be possible if we check the draft?\", 1],\n",
        "    [\"The depreciation of fixed assets amounts to $5 million this year.\", 0],\n",
        "    [\"Please expedite the completion of the balance sheet.\", 0],\n",
        "    [\"Could you increase the maximum lending limit for us?\", 1],\n",
        "    [\"We should cut down on unnecessary expenses to improve our profit ratio.\", 0],\n",
        "    [\"What percentage of revenue are we spending for ads?\", 1],\n",
        "    [\"One of the objectives of internal auditing is to improve business efficiency.\", 0],\n",
        "    [\"Did you have any problems finding us?\", 1],\n",
        "    [\"How is your business going?\", 1],\n",
        "    [\"Not really well. I might just sell the business.\", 0],\n",
        "    [\"What line of business are you in?\", 1],\n",
        "    [\"He has been a valued client of our bank for many years.\", 0],\n",
        "    [\"Would you like for me to show you around our office?\", 1],\n",
        "    [\"It's the second door on your left down this hall.\", 0],\n",
        "    [\"This is the … I was telling you about earlier.\", 0],\n",
        "    [\"We would like to take you out to dinner tonight.\", 0],\n",
        "    [\"Could you reschedule my appointment for next Wednesday?\", 1],\n",
        "    [\"Would you like Japanese, Chinese, Italian, French or American?\", 1],\n",
        "    [\"Is there anything you prefer not to have?\", 1],\n",
        "    [\"Please give my regards to the staff back in San Francisco.\", 0],\n",
        "    [\"This is a little expression of our thanks.\", 0],\n",
        "    [\"Why don’t you come along with us to the party this evening?\", 1],\n",
        "    [\"Unfortunately, I have a prior engagement on that day.\", 0],\n",
        "    [\"I am very happy to see all of you today.\", 0],\n",
        "    [\"It is a great honor to be given this opportunity to present here.\", 0],\n",
        "    [\"The purpose of this presentation is to show you the new direction our business is taking in 2009.\", 0],\n",
        "    [\"Could you please elaborate on that?\", 1],\n",
        "    [\"What's your proposal?\", 1]\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwlfjBJVVKz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceClassifierCNN(chainer.ChainList):\n",
        "    \n",
        "    def __init__(self, in_channel, out_channel, filter_height_list, filter_width, out_size, max_sentence_size):\n",
        "        \"\"\"クラスの初期化\n",
        "        \n",
        "        Args:\n",
        "            in_channel: 入力チャネル数\n",
        "            out_channel: 出力チャネル数\n",
        "            filter_height_list: フィルター縦サイズの配列\n",
        "            filter_width: フィルター横サイズ\n",
        "            out_size: 分類ラベル数\n",
        "            max_sentence_size: 文章の長さの最大サイズ\n",
        "        \"\"\"\n",
        "        self.filter_height_list = filter_height_list\n",
        "        self.max_sentence_size = max_sentence_size\n",
        "        self.convolution_num = len(filter_height_list)\n",
        "        # Linkの定義\n",
        "        link_list = [L.Convolution2D(in_channel, out_channel, (i, filter_width), pad=0) for i in filter_height_list] # Convolution層用のLinkをフィルター毎に追加\n",
        "        link_list.append(L.Linear(out_channel * self.convolution_num, out_channel * self.convolution_num)) # 隠れ層\n",
        "        link_list.append(L.Linear(out_channel * self.convolution_num, out_size)) # 出力層\n",
        "        # 定義したLinkのリストを用いてクラスを初期化する\n",
        "        super(SentenceClassifierCNN, self).__init__(*link_list)\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        \"\"\"順伝播の計算を行う関数\n",
        "        \n",
        "        Args:\n",
        "            x: 入力値\n",
        "        Returns:\n",
        "            y:\n",
        "        \"\"\"\n",
        "        # フィルタを通した結果を格納する配列\n",
        "        xcs = [None for i in self.filter_height_list]\n",
        "        chs = [None for i in self.filter_height_list]\n",
        "        # フィルタごとにループ\n",
        "        for i, filter_height in enumerate(self.filter_height_list):\n",
        "            xcs[i] = F.relu(self[i](x))\n",
        "            chs[i] = F.max_pooling_2d(xcs[i], (self.max_sentence_size+1-filter_height))\n",
        "        # Convolution+Poolingの結果の結合\n",
        "        h = F.concat(chs, axis=2)\n",
        "        h = F.dropout(F.tanh(self[self.convolution_num+0](h)))\n",
        "        y = self[self.convolution_num+1](h)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grjq2LPCVNTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = len(data)\n",
        "data_x, data_t = [], []\n",
        "for d in data:\n",
        "    data_x.append(d[0]) # 文書\n",
        "    data_t.append(d[1]) # ラベル\n",
        "\n",
        "def sentence2words(sentence):\n",
        "    stopwords = [\"i\", \"a\", \"an\", \"the\", \"and\", \"or\", \"if\", \"is\", \"are\", \"am\", \"it\", \"this\", \"that\", \"of\", \"from\", \"in\", \"on\"]\n",
        "    sentence = sentence.lower() # 小文字化\n",
        "    sentence = sentence.replace(\"\\n\", \"\") # 改行削除\n",
        "    sentence = re.sub(re.compile(r\"[!-\\/:-@[-`{-~]\"), \" \", sentence) # 記号をスペースに置き換え\n",
        "    sentence = sentence.split(\" \") # スペースで区切る\n",
        "    sentence_words = []\n",
        "    for word in sentence:\n",
        "        if (re.compile(r\"^.*[0-9]+.*$\").fullmatch(word) is not None): # 数字が含まれるものは除外\n",
        "            continue\n",
        "        if word in stopwords: # ストップワードに含まれるものは除外\n",
        "            continue\n",
        "        sentence_words.append(word)        \n",
        "    return sentence_words\n",
        "\n",
        "# 単語辞書\n",
        "words = {}\n",
        "for sentence in data_x:\n",
        "    sentence_words = sentence2words(sentence)\n",
        "    for word in sentence_words:\n",
        "        if word not in words:\n",
        "            words[word] = len(words)\n",
        "\n",
        "# 文章を単語ベクトル配列にする\n",
        "data_x_vec = []\n",
        "for sentence in data_x:\n",
        "    sentence_words = sentence2words(sentence)\n",
        "    sentence_vec = []\n",
        "    for word in sentence_words:\n",
        "        word_vec = np.zeros((len(words)))\n",
        "        word_vec[words[word]] = 1\n",
        "        sentence_vec.append(word_vec)\n",
        "    data_x_vec.append(sentence_vec)\n",
        "\n",
        "# 文章の長さを揃えるため、ゼロパディングする\n",
        "max_sentence_size = 0\n",
        "for sentence_vec in data_x_vec:\n",
        "    if max_sentence_size < len(sentence_vec):\n",
        "        max_sentence_size = len(sentence_vec)\n",
        "for sentence_vec in data_x_vec:\n",
        "    while len(sentence_vec) < max_sentence_size:\n",
        "        sentence_vec.append(np.zeros((len(words))))\n",
        "\n",
        "# データセット\n",
        "data_x_vec = np.array(data_x_vec, dtype=\"float32\")\n",
        "data_t = np.array(data_t, dtype=\"int32\")\n",
        "dataset = []\n",
        "for x, t in zip(data_x_vec, data_t):\n",
        "    dataset.append((x.reshape(1, max_sentence_size, len(words)), t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC3TXbN2VQ-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu = 0\n",
        "\n",
        "# 定数\n",
        "epoch_num = 10\n",
        "batch_size = 5\n",
        "out_size = 2\n",
        "filter_height_list = [1,2,3]\n",
        "out_channel = 32\n",
        "\n",
        "# モデルの定義\n",
        "model = L.Classifier(SentenceClassifierCNN(\n",
        "    in_channel=1,\n",
        "    out_channel=out_channel,\n",
        "    filter_height_list=filter_height_list,\n",
        "    filter_width=len(words),\n",
        "    out_size=out_size,\n",
        "    max_sentence_size=max_sentence_size\n",
        "))\n",
        "\n",
        "optimizer = chainer.optimizers.Adam()\n",
        "optimizer.setup(model)\n",
        "\n",
        "if gpu >= 0:\n",
        "    \n",
        "    chainer.cuda.get_device(gpu).use()\n",
        "    model.to_gpu(gpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU6KeXOeVSw_",
        "colab_type": "code",
        "outputId": "58e0b52d-e1bd-4ef4-eb2a-840c7a629a10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# 学習\n",
        "\n",
        "train, test = chainer.datasets.split_dataset_random(dataset, N-20)\n",
        "train_iter = chainer.iterators.SerialIterator(train, batch_size)\n",
        "test_iter = chainer.iterators.SerialIterator(test, batch_size, repeat=False, shuffle=False)\n",
        "updater = chainer.training.StandardUpdater(train_iter, optimizer, device=gpu)\n",
        "trainer = chainer.training.Trainer(updater, (epoch_num, \"epoch\"), out=\"result\")\n",
        "trainer.extend(extensions.Evaluator(test_iter, model, device=gpu))\n",
        "trainer.extend(extensions.LogReport(trigger=(1, \"epoch\")))\n",
        "trainer.extend(extensions.PrintReport( [\"epoch\", \"main/loss\", \"validation/main/loss\", \"main/accuracy\", \"validation/main/accuracy\", \"elapsed_time\"]))\n",
        "#trainer.extend(extensions.ProgressBar()) # プログレスバー出力\n",
        "trainer.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
            "\u001b[J1           0.698077    0.6902                0.6            0.55                      0.0919376     \n",
            "\u001b[J2           0.674164    0.686691              0.542857       0.55                      0.194717      \n",
            "\u001b[J3           0.653516    0.684227              0.666667       0.55                      0.294735      \n",
            "\u001b[J4           0.626934    0.682688              0.857143       0.6                       0.39747       \n",
            "\u001b[J5           0.615515    0.679652              0.766667       0.65                      0.492704      \n",
            "\u001b[J6           0.54016     0.674049              0.971429       0.45                      0.598433      \n",
            "\u001b[J7           0.533044    0.669157              0.942857       0.45                      0.705415      \n",
            "\u001b[J8           0.469153    0.66412               0.966667       0.45                      0.804957      \n",
            "\u001b[J9           0.408502    0.65849               1              0.45                      0.906959      \n",
            "\u001b[J10          0.349565    0.6502                1              0.55                      1.00683       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iIvnuolWG7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}